#!/usr/bin/env python3
"""
olstune
OpenLiteSpeed httpd_config.conf enforcer for Enhance hosting environments.
Enforces key/value pairs defined in settings.conf whenever the file changes.
Called by webservertune-enhance main program.
"""

import os
import shutil
import subprocess
import threading
import time
from datetime import datetime
from pathlib import Path

OLS_CONF    = Path("/usr/local/lsws/conf/httpd_config.conf")
OLS_LOG_DIR = Path("/var/local/enhance/webserver_logs")
BACKUP_BASE = Path("/opt/webservertune-enhance/backups/ols")
OLS_RESTART = ["/usr/local/lsws/bin/lswsctrl", "restart"]


# ---------------------------------------------------------------------------
# OLS site watcher — single inotify for all OLS consumers
# ---------------------------------------------------------------------------

class OLSSiteWatcher:
    def __init__(self, logger):
        self._logger    = logger
        self._lock      = threading.Lock()
        self._known     = set()
        self._consumers = []

    def register_consumer(self, on_add, on_remove):
        with self._lock:
            self._consumers.append((on_add, on_remove))
            known_snapshot = set(self._known)
        for uuid in known_snapshot:
            on_add(uuid)

    def start(self):
        try:
            for f in OLS_LOG_DIR.iterdir():
                if f.suffix == ".log":
                    self._known.add(f.stem)
        except OSError as e:
            self._logger.error(f"[OLSSiteWatcher] Cannot scan {OLS_LOG_DIR}: {e}")

        t = threading.Thread(target=self._inotify_loop, daemon=True)
        t.start()
        self._logger.info(f"[OLSSiteWatcher] Started, {len(self._known)} sites found")

    def _fire_add(self, uuid):
        with self._lock:
            if uuid in self._known:
                return
            self._known.add(uuid)
            consumers = list(self._consumers)
        for on_add, _ in consumers:
            on_add(uuid)

    def _fire_remove(self, uuid):
        with self._lock:
            if uuid not in self._known:
                return
            self._known.discard(uuid)
            consumers = list(self._consumers)
        for _, on_remove in consumers:
            on_remove(uuid)

    def _inotify_loop(self):
        cmd = [
            "inotifywait", "--monitor", "--quiet",
            "--format", "%e %f",
            "--event", "create",
            "--event", "delete",
            str(OLS_LOG_DIR),
        ]
        while True:
            try:
                proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, text=True)
            except Exception as e:
                self._logger.error(f"[OLSSiteWatcher] inotifywait failed: {e}")
                time.sleep(5)
                continue
            for line in proc.stdout:
                parts = line.strip().split(" ", 1)
                if len(parts) != 2:
                    continue
                event, fname = parts
                if not fname.endswith(".log"):
                    continue
                uuid = fname[:-4]
                if "CREATE" in event:
                    self._fire_add(uuid)
                elif "DELETE" in event:
                    self._fire_remove(uuid)
            proc.wait()
            self._logger.warning("[OLSSiteWatcher] inotifywait exited, restarting in 5s")
            time.sleep(5)


# ---------------------------------------------------------------------------
# inotify watch + debounce
# ---------------------------------------------------------------------------

def watch(config, logger, site_watcher):
    """Entry point called by main program. Runs startup check then watches for changes."""
    logger.info("olstune starting")
    run(config, logger)

    _start_ols_log_threads(config, logger, site_watcher)

    watch_dir     = str(OLS_CONF.parent)
    debounce_secs = config.get("general", {}).get("debounce_seconds", 10)

    cmd = [
        "inotifywait", "--monitor", "--quiet",
        "--format", "%e %f",
        "--event", "modify",
        "--event", "create",
        "--event", "moved_to",
        watch_dir,
    ]

    debounce_timer = None
    debounce_lock  = threading.Lock()

    def debounced_run():
        run(config, logger)

    def schedule_debounce():
        nonlocal debounce_timer
        with debounce_lock:
            if debounce_timer is not None:
                debounce_timer.cancel()
            debounce_timer = threading.Timer(debounce_secs, debounced_run)
            debounce_timer.start()

    def watch_loop():
        while True:
            try:
                logger.info(f"Watching {watch_dir} via inotifywait")
                proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, text=True)
            except FileNotFoundError:
                logger.error("inotifywait not found — install inotify-tools: apt install inotify-tools")
                return
            except Exception as e:
                logger.error(f"Failed to start inotifywait: {e}")
                time.sleep(5)
                continue

            for line in proc.stdout:
                parts = line.strip().split(" ", 1)
                if len(parts) == 2 and parts[1] == OLS_CONF.name:
                    logger.info(f"inotify event: {line.strip()}")
                    logger.debug(f"inotify event: {line.strip()}")
                    schedule_debounce()

            ret = proc.wait()
            logger.warning(f"inotifywait exited (code {ret}), restarting watch in 5s")
            time.sleep(5)

    watcher = threading.Thread(target=watch_loop, daemon=True)
    watcher.start()
    watcher.join()


# ---------------------------------------------------------------------------
# Main run: backup → enforce → restart
# ---------------------------------------------------------------------------

def run(config, logger):
    if not OLS_CONF.exists():
        logger.error(f"OLS config not found: {OLS_CONF}")
        return

    logger.debug("Running enforcement check")

    ols_config = config.get("ols-webserver", {})
    lines      = OLS_CONF.read_text().splitlines(keepends=True)
    changed    = False

    for section, desired in ols_config.items():
        if section == "backup_retention_days":
            continue
        if not isinstance(desired, dict):
            continue
        if section.lower() == "general":
            logger.debug("Enforcing section: general (top-level keys)")
            lines, section_changed = _enforce_general(lines, desired, logger)
        else:
            logger.debug(f"Enforcing block: '{section}'")
            lines, section_changed = _enforce_block(lines, section, desired, logger)
        if section_changed:
            changed = True

    if not changed:
        logger.info("All target values correct, no changes needed")
        return

    _create_backup(logger)

    logger.info("Writing updated config")
    OLS_CONF.write_text("".join(lines))

    logger.debug("Triggering OLS restart")
    _restart_ols(logger)


# ---------------------------------------------------------------------------
# Backup
# ---------------------------------------------------------------------------

def _create_backup(logger):
    backup_path = BACKUP_BASE / datetime.now().strftime("%Y%m%d_%H%M%S")
    try:
        backup_path.mkdir(parents=True, exist_ok=True)
        shutil.copy2(OLS_CONF, backup_path / OLS_CONF.name)
        logger.info(f"Backup created: {backup_path}")
    except Exception as e:
        logger.error(f"Failed to create backup: {e}")


# ---------------------------------------------------------------------------
# OLS restart
# ---------------------------------------------------------------------------

def _restart_ols(logger):
    try:
        result = subprocess.run(OLS_RESTART, capture_output=True, text=True)
        if result.returncode == 0:
            logger.info("OLS restart successful")
        else:
            logger.error(f"OLS restart failed: {result.stderr.strip()}")
    except Exception as e:
        logger.error(f"OLS restart error: {e}")


# ---------------------------------------------------------------------------
# Config enforcers
# ---------------------------------------------------------------------------

def _enforce_general(lines, desired, logger):
    new_lines     = []
    changed       = False
    keys_seen     = set()
    insert_before = None
    depth         = 0

    desired_lower = {k.lower(): (k, v) for k, v in desired.items()}

    for line in lines:
        stripped = line.strip()

        if stripped.endswith("{"):
            if depth == 0 and insert_before is None:
                insert_before = len(new_lines)
            depth += stripped.count("{")
        if "}" in stripped:
            depth -= stripped.count("}")

        if depth == 0:
            parts = stripped.split(None, 1)
            if len(parts) == 2:
                indent = line[: len(line) - len(line.lstrip())]
                key_lower = parts[0].lower()
                if key_lower in desired_lower:
                    keys_seen.add(key_lower)
                    key_out, val_out = desired_lower[key_lower]
                    current_val = parts[1].strip()
                    if current_val != val_out:
                        new_lines.append(f"{indent}{key_out:<26}{val_out}\n")
                        logger.info(f"  AMENDED  {key_out}: '{current_val}' -> '{val_out}'")
                        changed = True
                        continue

        new_lines.append(line)

    if insert_before is None:
        insert_before = len(new_lines)

    # Walk backwards past any blank lines so insertions land with the other keys
    while insert_before > 0 and not new_lines[insert_before - 1].strip():
        insert_before -= 1

    inserts = []
    for key_lower, (key_out, val_out) in desired_lower.items():
        if key_lower not in keys_seen:
            inserts.append(f"        {key_out:<26}{val_out}\n")
            logger.info(f"  INSERTED {key_out} = {val_out}")
            changed = True

    if inserts:
        new_lines = new_lines[:insert_before] + inserts + new_lines[insert_before:]

    return new_lines, changed


def _enforce_block(lines, target_block, desired, logger):
    new_lines     = []
    changed       = False
    in_block      = False
    depth         = 0
    keys_seen     = set()
    block_found   = False
    block_indent  = "  "
    insert_before = None

    desired_lower = {k.lower(): (k, v) for k, v in desired.items()}

    i = 0
    while i < len(lines):
        line     = lines[i]
        stripped = line.strip()

        if not in_block:
            normalised = " ".join(stripped.rstrip("{").split()).lower()
            if normalised == target_block.lower() and stripped.endswith("{"):
                in_block    = True
                block_found = True
                depth       = 1
                new_lines.append(line)
                i += 1
                continue

        if in_block:
            if "{" in stripped:
                depth += stripped.count("{")
            if "}" in stripped:
                depth -= stripped.count("}")

            if depth == 0:
                # Find insert point by walking back past blank lines
                insert_before = len(new_lines)
                while insert_before > 0 and not new_lines[insert_before - 1].strip():
                    insert_before -= 1

                inserts = []
                for key_lower, (key_out, val_out) in desired_lower.items():
                    if key_lower not in keys_seen:
                        inserts.append(f"{block_indent}{key_out:<24}{val_out}\n")
                        logger.info(f"  INSERTED {key_out} = {val_out}")
                        changed = True

                if inserts:
                    new_lines = new_lines[:insert_before] + inserts + new_lines[insert_before:]

                in_block = False
                new_lines.append(line)
                i += 1
                continue

            parts = stripped.split(None, 1)
            if len(parts) == 2 and depth == 1:
                current_indent = line[: len(line) - len(line.lstrip())]
                if current_indent:
                    block_indent = current_indent
                key_lower = parts[0].lower()
                if key_lower in desired_lower:
                    keys_seen.add(key_lower)
                    key_out, val_out = desired_lower[key_lower]
                    current_val = parts[1].strip()
                    if current_val != val_out:
                        indent = line[: len(line) - len(line.lstrip())]
                        new_lines.append(f"{indent}{key_out:<24}{val_out}\n")
                        logger.info(f"  AMENDED  {key_out}: '{current_val}' -> '{val_out}'")
                        changed = True
                        i += 1
                        continue

        new_lines.append(line)
        i += 1

    if not block_found:
        logger.warning(f"Block '{target_block}' not found in config")

    return new_lines, changed


# ---------------------------------------------------------------------------
# Log directory helper
# ---------------------------------------------------------------------------

def _ensure_log_dir(uuid, logger):
    logs_dir = Path(f"/var/www/{uuid}/logs")
    try:
        if not logs_dir.exists():
            logs_dir.mkdir(parents=True, mode=0o755)
            parent_stat = os.stat(f"/var/www/{uuid}")
            os.chown(logs_dir, parent_stat.st_uid, parent_stat.st_gid)

        parent_stat = os.stat(f"/var/www/{uuid}")
        for lf in logs_dir.iterdir():
            if lf.is_file():
                fs          = os.stat(lf)
                wrong_owner = fs.st_uid != parent_stat.st_uid or fs.st_gid != parent_stat.st_gid
                wrong_perms = (fs.st_mode & 0o777) != 0o644
                if wrong_owner or wrong_perms:
                    if wrong_owner:
                        os.chown(lf, parent_stat.st_uid, parent_stat.st_gid)
                    if wrong_perms:
                        os.chmod(lf, 0o644)
    except Exception as e:
        logger.error(f"Failed to set up log directory for {uuid}: {e}")


# ---------------------------------------------------------------------------
# FileWatcher — tails a file, handles rotation and truncation
# ---------------------------------------------------------------------------

class FileWatcher:
    def __init__(self, path, logger, seek_to_end_on_open=True):
        self.path                = path
        self.logger              = logger
        self.seek_to_end_on_open = seek_to_end_on_open
        self.fh                  = None
        self.inode               = None
        self.position            = 0
        self._open()

    def _open(self):
        try:
            self.fh = open(self.path, "r", errors="replace")
            self.inode = os.fstat(self.fh.fileno()).st_ino
            if self.seek_to_end_on_open:
                self.fh.seek(0, 2)
            self.position = self.fh.tell()
            self.logger.debug(f"Opened: {self.path} (inode {self.inode})")
        except OSError:
            self.fh    = None
            self.inode = None

    def _reopen_if_needed(self):
        try:
            stat = os.stat(self.path)
        except OSError:
            if self.fh:
                self.fh.close()
                self.fh    = None
                self.inode = None
            return

        if self.fh is None:
            self._open()
            return

        if stat.st_ino != self.inode:
            self.logger.debug(f"Recreated: {self.path}")
            self.fh.close()
            self._open()
            return

        if stat.st_size < self.position:
            self.logger.debug(f"Truncated: {self.path}")
            self.fh.seek(0)
            self.position = 0

    def readlines(self):
        self._reopen_if_needed()
        if self.fh is None:
            return []
        lines         = self.fh.readlines()
        self.position = self.fh.tell()
        return lines

    def close(self):
        if self.fh:
            self.fh.close()


# ---------------------------------------------------------------------------
# _DestFile — keeps a destination log file handle open in append mode
# ---------------------------------------------------------------------------

class _DestFile:
    def __init__(self, path, logger):
        self.path   = path
        self.logger = logger
        self.fh     = None
        self._open()

    def _open(self):
        try:
            self.fh = open(self.path, "a")
        except OSError as e:
            self.logger.error(f"Cannot open dest file {self.path}: {e}")
            self.fh = None

    def write(self, line):
        if self.fh is None:
            self._open()
            if self.fh is None:
                return
        try:
            self.fh.write(line)
            self.fh.flush()
        except OSError:
            self.fh = None
            self._open()
            if self.fh:
                try:
                    self.fh.write(line)
                    self.fh.flush()
                except OSError as e:
                    self.logger.error(f"Failed to write to {self.path}: {e}")

    def close(self):
        if self.fh:
            self.fh.close()
            self.fh = None


# ---------------------------------------------------------------------------
# OLS persistent log threads
# ---------------------------------------------------------------------------

def _start_ols_log_threads(config, logger, site_watcher):
    """Start OLS log persistence threads if enabled."""
    general = config.get("general", {})

    if general.get("persistent_logging", False):
        t = threading.Thread(
            target=_ols_webserver_log_watcher,
            args=(logger, site_watcher),
            daemon=True
        )
        t.start()
        logger.info("OLS webserver log persistence thread started")

    if general.get("persistent_php_logs", False):
        t = threading.Thread(
            target=_ols_php_log_watcher,
            args=(logger, site_watcher),
            daemon=True
        )
        t.start()
        logger.info("OLS PHP log persistence thread started")


def _ols_webserver_log_watcher(logger, site_watcher):
    """
    Tails /var/local/enhance/webserver_logs/{uuid}.log into
    /var/www/{uuid}/logs/webserver.log for each active OLS site.
    """
    registry = {}
    reg_lock = threading.Lock()

    def on_add(uuid):
        with reg_lock:
            if uuid in registry:
                return
            _ensure_log_dir(uuid, logger)
            registry[uuid] = {
                "src":  FileWatcher(str(OLS_LOG_DIR / f"{uuid}.log"), logger, seek_to_end_on_open=False),
                "dest": _DestFile(Path(f"/var/www/{uuid}/logs/webserver.log"), logger),
            }
            logger.debug(f"[ols_webserver_log] Registered: {uuid}")

    def on_remove(uuid):
        with reg_lock:
            entry = registry.pop(uuid, None)
            if entry:
                entry["src"].close()
                entry["dest"].close()
                logger.debug(f"[ols_webserver_log] Unregistered: {uuid}")

    site_watcher.register_consumer(on_add, on_remove)

    cycle = 0
    while True:
        with reg_lock:
            snapshot = list(registry.items())
        for uuid, entry in snapshot:
            if cycle % 60 == 0:
                _ensure_log_dir(uuid, logger)
            for line in entry["src"].readlines():
                if line.strip():
                    entry["dest"].write(line)
        cycle += 1
        time.sleep(1)


def _ols_php_log_watcher(logger, site_watcher):
    """
    Tails /var/www/{uuid}/php-error.log into /var/www/{uuid}/logs/php.log
    for each active OLS site. OLS does not produce php-fpm.log.
    """
    registry = {}
    reg_lock = threading.Lock()

    def on_add(uuid):
        with reg_lock:
            if uuid in registry:
                return
            _ensure_log_dir(uuid, logger)
            registry[uuid] = {
                "src":  FileWatcher(f"/var/www/{uuid}/php-error.log", logger, seek_to_end_on_open=False),
                "dest": _DestFile(Path(f"/var/www/{uuid}/logs/php.log"), logger),
            }
            logger.debug(f"[ols_php_log] Registered: {uuid}")

    def on_remove(uuid):
        with reg_lock:
            entry = registry.pop(uuid, None)
            if entry:
                entry["src"].close()
                entry["dest"].close()
                logger.debug(f"[ols_php_log] Unregistered: {uuid}")

    site_watcher.register_consumer(on_add, on_remove)

    cycle = 0
    while True:
        with reg_lock:
            snapshot = list(registry.items())
        for uuid, entry in snapshot:
            if cycle % 60 == 0:
                _ensure_log_dir(uuid, logger)
            for line in entry["src"].readlines():
                if line.strip():
                    entry["dest"].write(line)
        cycle += 1
        time.sleep(1)
